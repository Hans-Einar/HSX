# Debug Metadata Implementation Plan

## Overview
This document specifies the implementation of debug metadata preservation through the HSX toolchain, enabling source-level debugging with line numbers, function names, and variable tracking.

## Design References
- Design: [04.05--Toolchain.md](../../04--Design/04.05--Toolchain.md) Section 4.2.1, 4.2.3
- Design: [04.02--Executive.md](../../04--Design/04.02--Executive.md) Sections 5.3-5.7
- Design: [04.09--Debugger.md](../../04--Design/04.09--Debugger.md) Section 5.5.7-5.5.9
- Review: [DebuggerDesignReview.md](../../04--Design/DebuggerDesignReview.md) Section 1.4

## Implementation Phases

### Phase 1: Function-Level Debug Info (MVP)
**Goal:** Enable basic disassembly with function names and start lines.

**Components:**
1. **hsx-llc.py**: Parse `!DISubprogram` / `!DIFile` nodes and surface function metadata in the intermediate IR
2. **Linker (hld.py)**: Generate .sym file with function list
3. **Executive**: Load .sym file and provide symbol lookup

**Deliverables:**
- `hsx-llc.py --emit-debug <file>` flag
- Intermediate .dbg JSON format (function-level only)
- `hld.py --debug-info <.dbg> --emit-sym <file>` flags
- .sym JSON format (functions only)
- Executive symbol loading and `symbols.list` API

**Extraction Workflow (hsx-llc)**
1. Scan the LLVM IR for metadata definitions (`!123 = ...`) and accumulate `!DIFile` and `!DISubprogram` records, transparently handling multi-line entries.
2. When a function definition includes a `!dbg !<id>` attachment, record the link between the function and the previously parsed `!DISubprogram`.
3. Emit an intermediate IR structure with:
   - `debug.files` mapping metadata ids to `{"filename", "directory"}`
   - `debug.subprograms` containing the raw `!DISubprogram` fields (name, linkageName, file ref, line)
   - `debug.functions` summarising each function (sanitised name, associated file metadata, start line).
4. Later phases consume this structure when generating `.dbg` and `.sym` artefacts.

### Phase 2: Instruction-Level Line Tracking
**Goal:** Map every instruction to source line/column for accurate debugging.

**Components:**
1. **hsx-llc.py**: Parse `!DILocation` nodes, track LLVM→MVASM mappings
2. **Linker (hld.py)**: Map MVASM→HXE addresses, include line info in .sym
3. **Executive**: Provide line info in disassembly API

**Deliverables:**
- Enhanced .dbg format with line mappings
- Enhanced .sym format with instruction-level line info
- `disasm.read` API returns file/line for each instruction

### Phase 3: Variable Tracking
**Goal:** Enable watch expressions on local and global variables.

**Components:**
1. **hsx-llc.py**: Parse `!DILocalVariable`, track variable locations
2. **Linker (hld.py)**: Include variable symbols in .sym
3. **Executive**: Variable name resolution for watch expressions

**Deliverables:**
- .sym format includes variable symbols
- `watch.add` accepts symbol names
- Stack frame local variable display

## File Formats

### Intermediate .dbg JSON Format
Generated by hsx-llc.py, consumed by linker:

```json
{
  "version": 1,
  "source_files": ["main.c", "utils.c"],
  "functions": [
    {
      "name": "main",
      "file": "main.c",
      "start_line": 10,
      "end_line": 25,
      "mvasm_start_line": 42,
      "mvasm_end_line": 84,
      "mvasm_start_ordinal": 0,
      "mvasm_end_ordinal": 19,
      "register_allocation": {
        "available_registers": 7,
        "max_pressure": 3,
        "spill_count": 0,
        "reload_count": 0,
        "proactive_splits": 0,
        "stack_slots": 0,
        "stack_bytes": 0,
        "used_register_count": 3,
        "used_registers": ["R4", "R5", "R6"]
      }
    },
    {
      "name": "add",
      "file": "utils.c",
      "start_line": 5,
      "end_line": 8,
      "mvasm_start_line": 120,
      "mvasm_end_line": 140,
      "mvasm_start_ordinal": 32,
      "mvasm_end_ordinal": 41
    }
  ],
  "line_map": [
    {
      "mvasm_line": 5,
      "source_file": "main.c",
      "source_file_id": "!12",
      "source_directory": "src",
      "source_line": 12,
      "source_column": 5,
      "mvasm_ordinal": 2
    },
    {
      "mvasm_line": 10,
      "source_file": "main.c",
      "source_file_id": "!12",
      "source_directory": "src",
      "source_line": 13,
      "source_column": 9,
      "mvasm_ordinal": 4
    }
  ],
  "variables": [
    {
      "name": "counter",
      "type": "int",
      "scope": "global",
      "mvasm_addr": 0,
      "size": 4
    },
    {
      "name": "result",
      "type": "int",
      "scope": "local",
      "function": "main",
      "stack_offset": -4
    }
  ],
  "llvm_to_mvasm": [
    {
      "id": "main@1",
      "function": "main",
      "ir": "%6 = load i32, ptr %dst",
      "raw_ir": "%6 = load i32, ptr %dst, align 4",
      "mvasm_lines": [5, 6],
      "mvasm_ordinals": [2, 3],
      "source_line": 12,
      "source_file": "main.c"
    },
    {
      "id": "main@2",
      "function": "main",
      "ir": "%8 = add i32 %6, %7",
      "raw_ir": "%8 = add i32 %6, %7",
      "mvasm_lines": [10],
      "mvasm_ordinals": [4],
      "source_line": 13,
      "source_file": "main.c"
    }
  ]
}
```

`register_allocation` is optional and appears when lowering captures allocator statistics. The object reports:

- `available_registers`: number of caller-saved registers eligible for allocation.
- `max_pressure`: peak number of simultaneously occupied registers during lowering.
- `spill_count` / `reload_count`: number of store/load pairs emitted to service spills.
- `proactive_splits`: number of proactively split live ranges (values spilled early to reduce pressure).
- `stack_slots` / `stack_bytes`: spill slot count and total stack frame bytes reserved by the allocator.
- `used_register_count` / `used_registers`: unique registers assigned to temporaries (useful for performance profiling).

The top-level payload also exposes `register_allocation_summary` aggregating metrics across all lowered functions:

```json
{
  "register_allocation_summary": {
    "total_functions": 4,
    "functions_with_spills": ["foo", "bar"],
    "max_pressure": 5,
    "total_spills": 12,
    "total_reloads": 12,
    "max_stack_bytes": 32,
    "total_proactive_splits": 5
  }
}
```

Tooling can use the summary for quick profiling without inspecting each function individually.

*Current implementation*: `hsx-llc --emit-debug` produces `files`/`functions`/`line_map`/`llvm_to_mvasm` with MVASM ordinals, and the linker consumes this data to emit `.sym` files (functions, variables, labels, instructions, memory regions) when `--emit-sym` is provided.

### Final .sym JSON Format
Generated by linker, consumed by executive and debugger:

```json
{
  "version": 1,
  "hxe_path": "app.hxe",
  "hxe_crc": 0x12345678,
  "symbols": {
    "functions": [
      {
        "name": "main",
        "address": 0x0100,
        "size": 64,
        "file": "main.c",
        "line": 10
      },
      {
        "name": "add",
        "address": 0x0140,
        "size": 20,
        "file": "utils.c",
        "line": 5
      }
    ],
    "variables": [
      {
        "name": "counter",
        "address": 0x2000,
        "size": 4,
        "type": "int",
        "scope": "global"
      }
    ],
    "labels": {
      "0x0100": ["main", "_start"],
      "0x0120": ["loop_top"],
      "0x0140": ["add"]
    }
  },
  "instructions": [
    {
      "pc": 0x0100,
      "word": 0x01020304,
      "mnemonic": "LDI",
      "operands": "R1, 0x5",
      "file": "main.c",
      "line": 12,
      "column": 5
    },
    {
      "pc": 0x0104,
      "word": 0x10120000,
      "mnemonic": "ADD",
      "operands": "R1, R2, R0",
      "file": "main.c",
      "line": 13,
      "column": 9
    }
  ],
  "memory_regions": [
    {
      "name": "code",
      "start": 0x0000,
      "end": 0x1FFF,
      "type": "text"
    },
    {
      "name": "data",
      "start": 0x2000,
      "end": 0x2FFF,
      "type": "data"
    },
    {
      "name": "stack",
      "start": 0x7000,
      "end": 0x7FFF,
      "type": "stack"
    }
  ]
}
```

## hsx-llc.py Implementation

### LLVM Debug Metadata Nodes
When Clang compiles with `-g`, it embeds debug metadata:

```llvm
; Function with debug info
define i32 @add(i32 %0, i32 %1) !dbg !10 {
  %8 = add nsw i32 %6, %7, !dbg !23
  ret i32 %9, !dbg !25
}

; Metadata nodes
!10 = distinct !DISubprogram(name: "add", file: !1, line: 1, ...)
!23 = !DILocation(line: 2, column: 20, scope: !10)
```

### Debug Info Extraction

```python
class DebugInfo:
    def __init__(self):
        self.files = {}          # !N -> {filename, directory}
        self.subprograms = {}    # !N -> {name, file, line}
        self.locations = {}      # !N -> {line, column, scope}
        self.variables = {}      # !N -> {name, type, scope}
    
    def parse_metadata_line(self, line: str):
        """Parse debug metadata nodes from LLVM IR"""
        # !10 = distinct !DISubprogram(name: "add", file: !1, line: 1, ...)
        if '!DISubprogram' in line:
            node_id, attrs = self._parse_di_node(line)
            self.subprograms[node_id] = {
                'name': self._unquote(attrs.get('name')),
                'file': attrs.get('file'),
                'line': int(attrs.get('line', 0)),
                'scope': attrs.get('scope')
            }
        
        # !16 = !DILocation(line: 1, column: 13, scope: !10)
        elif '!DILocation' in line:
            node_id, attrs = self._parse_di_node(line)
            self.locations[node_id] = {
                'line': int(attrs.get('line', 0)),
                'column': int(attrs.get('column', 0)),
                'scope': attrs.get('scope')
            }
        
        # !1 = !DIFile(filename: "test.c", directory: "/path")
        elif '!DIFile' in line:
            node_id, attrs = self._parse_di_node(line)
            self.files[node_id] = {
                'filename': self._unquote(attrs.get('filename')),
                'directory': self._unquote(attrs.get('directory'))
            }
        
        # !15 = !DILocalVariable(name: "a", scope: !10, file: !1, line: 1, type: !13)
        elif '!DILocalVariable' in line:
            node_id, attrs = self._parse_di_node(line)
            self.variables[node_id] = {
                'name': self._unquote(attrs.get('name')),
                'scope': attrs.get('scope'),
                'file': attrs.get('file'),
                'line': int(attrs.get('line', 0)),
                'type': attrs.get('type')
            }
    
    def _parse_di_node(self, line: str) -> Tuple[str, Dict[str, str]]:
        """Parse metadata node and extract attributes"""
        # Example: !10 = distinct !DISubprogram(name: "add", file: !1, line: 1)
        match = re.match(r'!(\d+)\s*=\s*(?:distinct\s+)?!DI\w+\((.*)\)', line)
        if not match:
            return None, {}
        
        node_id = match.group(1)
        attrs_str = match.group(2)
        
        # Parse key: value pairs
        attrs = {}
        for part in attrs_str.split(','):
            if ':' in part:
                key, value = part.split(':', 1)
                attrs[key.strip()] = value.strip()
        
        return node_id, attrs
    
    def _unquote(self, s: str) -> str:
        """Remove quotes from string"""
        if s and s[0] == '"' and s[-1] == '"':
            return s[1:-1]
        return s

class HSXLowering:
    def __init__(self):
        self.debug_info = DebugInfo()
        self.instruction_locations = {}  # mvasm_line -> {line, column, file}
        self.mvasm_line = 0
    
    def process_ir_file(self, ir_lines: List[str]):
        """Process LLVM IR file"""
        # First pass: collect all metadata
        for line in ir_lines:
            if line.startswith('!'):
                self.debug_info.parse_metadata_line(line)
        
        # Second pass: lower instructions
        for line in ir_lines:
            if line.strip().startswith('define'):
                self.lower_function(line)
    
    def lower_instruction(self, llvm_inst: str):
        """Lower LLVM instruction and track debug location"""
        # Extract !dbg !N annotation
        dbg_match = re.search(r'!dbg !(\d+)', llvm_inst)
        if dbg_match:
            dbg_ref = dbg_match.group(1)
            if dbg_ref in self.debug_info.locations:
                loc = self.debug_info.locations[dbg_ref]
                scope = loc['scope']
                
                # Resolve file from scope
                file_ref = None
                if scope in self.debug_info.subprograms:
                    file_ref = self.debug_info.subprograms[scope]['file']
                
                filename = None
                if file_ref and file_ref in self.debug_info.files:
                    filename = self.debug_info.files[file_ref]['filename']
                
                # Store mapping
                self.instruction_locations[self.mvasm_line] = {
                    'line': loc['line'],
                    'column': loc['column'],
                    'file': filename
                }
        
        # ... rest of lowering logic ...
        self.mvasm_line += 1
    
    def emit_debug_file(self, output_path: str):
        """Write .dbg JSON file"""
        dbg_data = {
            'version': 1,
            'source_files': list(set(
                f['filename'] for f in self.debug_info.files.values()
            )),
            'functions': [],
            'line_map': [],
            'variables': []
        }
        
        # Collect functions
        for node_id, subprog in self.debug_info.subprograms.items():
            file_ref = subprog.get('file')
            filename = None
            if file_ref and file_ref in self.debug_info.files:
                filename = self.debug_info.files[file_ref]['filename']
            
            dbg_data['functions'].append({
                'name': subprog['name'],
                'file': filename,
                'start_line': subprog['line']
            })
        
        # Collect line mappings
        for mvasm_line, loc in sorted(self.instruction_locations.items()):
            dbg_data['line_map'].append({
                'mvasm_line': mvasm_line,
                'source_file': loc['file'],
                'source_line': loc['line'],
                'source_column': loc['column']
            })
        
        with open(output_path, 'w') as f:
            json.dump(dbg_data, f, indent=2)
```

### Command Line Integration

```python
# In main():
ap = argparse.ArgumentParser()
ap.add_argument('input', help='LLVM IR input file')
ap.add_argument('-o', '--output', required=True, help='MVASM output file')
ap.add_argument('--emit-debug', help='Generate debug info JSON file')
args = ap.parse_args()

# ... lowering logic ...

if args.emit_debug:
    lowering.emit_debug_file(args.emit_debug)
```

### Debug Prefix Mapping

To keep debug metadata portable, the build pipeline rewrites absolute source
paths using Clang's `-fdebug-prefix-map` option. When `hsx-cc-build.py` runs in
`--debug` mode it:

- Computes the mapping `<project_root>=.` based on the resolved project root.
- Appends `-fdebug-prefix-map=<project_root>=.` to every Clang invocation.
- Exposes the computed mapping via the environment variables
  `HSX_DEBUG_PREFIX_MAP` and `DEBUG_PREFIX_MAP` so custom Makefiles can reuse
  the value (for example `CFLAGS += -fdebug-prefix-map=$(DEBUG_PREFIX_MAP)`).

Tests assert that the builder passes the flag and that emitted `.dbg` records
reference relative directories whenever debug builds are requested.

For details on the generated source map file, see `docs/sources_json.md`.

## Linker Implementation

### Debug Info Merge

```python
def merge_debug_info(hxo_modules: List[Dict], dbg_files: List[str]) -> Dict:
    """Merge debug info from .dbg files with relocated addresses"""
    sym_data = {
        'version': 1,
        'symbols': {
            'functions': [],
            'variables': [],
            'labels': {}
        },
        'instructions': [],
        'memory_regions': []
    }
    
    # Load all .dbg files
    debug_info_list = []
    for dbg_path in dbg_files:
        with open(dbg_path) as f:
            debug_info_list.append(json.load(f))
    
    # Process each module
    for mod_idx, (module, dbg) in enumerate(zip(hxo_modules, debug_info_list)):
        base_addr = module['base_address']
        
        # Merge functions with relocated addresses
        for func in dbg.get('functions', []):
            sym_data['symbols']['functions'].append({
                'name': func['name'],
                'address': base_addr + func.get('mvasm_start', 0),
                'size': func.get('mvasm_end', 0) - func.get('mvasm_start', 0),
                'file': func['file'],
                'line': func['start_line']
            })
        
        # Merge line mappings
        for line_entry in dbg.get('line_map', []):
            mvasm_line = line_entry['mvasm_line']
            # Convert MVASM line to actual PC
            pc = base_addr + (mvasm_line * 4)  # Assuming 4 bytes per instruction
            
            sym_data['instructions'].append({
                'pc': pc,
                'file': line_entry['source_file'],
                'line': line_entry['source_line'],
                'column': line_entry.get('source_column', 0)
            })
    
    # Sort instructions by PC
    sym_data['instructions'].sort(key=lambda x: x['pc'])
    
    # Add memory regions from HXE header
    sym_data['memory_regions'] = [
        {
            'name': 'code',
            'start': 0x0000,
            'end': code_len - 1,
            'type': 'text'
        },
        {
            'name': 'data',
            'start': code_len,
            'end': code_len + rodata_len - 1,
            'type': 'data'
        }
    ]
    
    return sym_data

def emit_sym_file(sym_data: Dict, output_path: str, hxe_path: str, hxe_crc: int):
    """Write .sym JSON file"""
    sym_data['hxe_path'] = hxe_path
    sym_data['hxe_crc'] = hxe_crc
    
    with open(output_path, 'w') as f:
        json.dump(sym_data, f, indent=2)
```

### Command Line Integration

```python
# In main():
ap = argparse.ArgumentParser()
ap.add_argument('inputs', nargs='+', help='HXO input files')
ap.add_argument('-o', '--output', required=True, help='HXE output file')
ap.add_argument('--debug-info', nargs='+', help='.dbg debug info files')
ap.add_argument('--emit-sym', help='Generate .sym symbol file')
args = ap.parse_args()

# ... linking logic ...

if args.emit_sym and args.debug_info:
    sym_data = merge_debug_info(modules, args.debug_info)
    emit_sym_file(sym_data, args.emit_sym, args.output, hxe_crc)
```

## Executive Implementation

### Symbol Loading

```python
class SymbolTable:
    def __init__(self, sym_path: str):
        with open(sym_path) as f:
            self.data = json.load(f)
        
        # Build lookup indices
        self.pc_to_line = {}
        for inst in self.data.get('instructions', []):
            self.pc_to_line[inst['pc']] = {
                'file': inst['file'],
                'line': inst['line'],
                'column': inst.get('column', 0)
            }
        
        self.addr_to_symbol = {}
        for func in self.data['symbols']['functions']:
            self.addr_to_symbol[func['address']] = func['name']
    
    def lookup_symbol(self, addr: int) -> Optional[Dict]:
        """Find symbol at or before address"""
        # Find closest function before addr
        candidates = [
            f for f in self.data['symbols']['functions']
            if f['address'] <= addr < f['address'] + f['size']
        ]
        return candidates[0] if candidates else None
    
    def lookup_line(self, pc: int) -> Optional[Dict]:
        """Find source line for PC"""
        return self.pc_to_line.get(pc)

class Executive:
    def __init__(self):
        self.symbol_tables = {}  # pid -> SymbolTable
    
    def load_task(self, hxe_path: str, pid: int):
        """Load task and associated .sym file"""
        # ... load HXE ...
        
        # Try to load .sym file
        sym_path = hxe_path.replace('.hxe', '.sym')
        if os.path.exists(sym_path):
            self.symbol_tables[pid] = SymbolTable(sym_path)
    
    def handle_disasm_read(self, req: Dict) -> Dict:
        """Handle disasm.read RPC"""
        pid = req['pid']
        addr = req['addr']
        count = req['count']
        mode = req.get('mode', 'from_addr')
        
        # Get symbol table
        sym_table = self.symbol_tables.get(pid)
        
        # Disassemble instructions
        instructions = []
        # ... disassembly logic ...
        
        # Add symbol annotations
        for inst in instructions:
            if sym_table:
                line_info = sym_table.lookup_line(inst['pc'])
                if line_info:
                    inst['file'] = line_info['file']
                    inst['line'] = line_info['line']
                
                symbol = sym_table.lookup_symbol(inst['pc'])
                if symbol:
                    inst['symbol'] = symbol['name']
        
        return {
            'status': 'ok',
            'instructions': instructions,
            'has_symbols': sym_table is not None
        }
```

## Testing Strategy

### Unit Tests
- LLVM metadata parser (DebugInfo class)
- .dbg file generation
- .sym file generation
- Symbol table lookup

### Integration Tests
- Full toolchain: C source → LLVM IR → MVASM → HXO → HXE → .sym
- Verify line numbers match source
- Verify function boundaries correct
- Verify symbol lookups work

### Test Cases
1. Simple function with line numbers
2. Multiple functions in multiple files
3. Optimized code (lines may be reordered)
4. Code without debug info (graceful degradation)

## Rollout Plan

1. **Phase 1 MVP (Week 1-2)**
   - Implement function-level debug in hsx-llc.py
   - Implement .sym generation in linker
   - Implement symbol loading in executive
   - Test with simple examples

2. **Phase 2 Line Tracking (Week 3-4)**
   - Add instruction-level line tracking
   - Enhance .dbg and .sym formats
   - Update disasm.read API
   - Test with complex examples

3. **Phase 3 Variables (Week 5-6)**
   - Add variable tracking
   - Implement watch expression support
   - Full integration testing
   - Documentation

## Success Criteria
- [ ] TUI can display source file and line number for each instruction
- [ ] Breakpoint manager shows function names in tree view
- [ ] Stack trace shows file:line for each frame
- [ ] Watch expressions work with variable names
- [ ] Debug info overhead < 10% of HXE size
- [ ] .sym file loading time < 100ms for typical programs
